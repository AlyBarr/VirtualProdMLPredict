{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b585fa19-1a8c-4f1e-9895-d23eb87ecf9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully yay!\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 1. IMPORT REQUIRED LIBRARIES\n",
    "# -------------------------------------------------------------\n",
    "# These libraries handle:\n",
    "# - file reading (os, glob, Path)\n",
    "# - numerical and data manipulation (numpy, pandas)\n",
    "# - machine learning preprocessing (scikit-learn)\n",
    "# - model building and saving (pickle)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "import os, re, glob, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "\n",
    "print(\"Libraries imported successfully yay!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a98b134f-2950-4083-99a5-69c2b7906427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found files: 180\n",
      "['CleanedKARDDataset\\\\RealWorldCoordinates\\\\a01_s01_e01_realworld.csv', 'CleanedKARDDataset\\\\RealWorldCoordinates\\\\a01_s02_e01_realworld.csv', 'CleanedKARDDataset\\\\RealWorldCoordinates\\\\a01_s03_e01_realworld.csv']\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 2. LOAD AND VERIFY DATASET\n",
    "# -------------------------------------------------------------\n",
    "# The dataset comes from the CleanedKARDDataset ZIP you uploaded.\n",
    "# Each CSV file represents one action clip containing 3D joint positions\n",
    "# in real-world coordinates (x, y, z) for different body joints.\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Change this path if your folder is stored elsewhere\n",
    "DATA_DIR = Path(\"CleanedKARDDataset/RealWorldCoordinates\")  # change if needed\n",
    "\n",
    "# Make sure the folder exists before continuing\n",
    "assert DATA_DIR.exists(), f\"Data dir not found: {DATA_DIR}\"\n",
    "\n",
    "\n",
    "# Collect all CSV files in the folder\n",
    "files = sorted(glob.glob(str(DATA_DIR / \"*.csv\")))\n",
    "print(\"Found files:\", len(files))\n",
    "\n",
    "# Preview first few file names\n",
    "print(files[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0faff85f-8257-42f6-a6d6-c33ea9b143f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 3. PARSE SEQUENCES INTO ARRAYS\n",
    "# -------------------------------------------------------------\n",
    "# Each CSV lists joint coordinates for multiple frames.\n",
    "# Reconstructing the frames so each file becomes:\n",
    "#     seq shape = (T, J, 3)\n",
    "# where:\n",
    "#   T = number of frames\n",
    "#   J = number of joints\n",
    "#   3 = x, y, z coordinates\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "def parse_sequence(csv_path: str):\n",
    "    \"\"\"\n",
    "    Convert a single CSV into a 3D numpy array [frames, joints, coords].\n",
    "    'Head' rows are used to detect new frames in the CSV stream.\n",
    "    Returns:\n",
    "        seq  -> np.ndarray of shape (T, J, 3)\n",
    "        joint_order -> list of joint names in consistent order\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    frames = []     # stores frame DataFrames\n",
    "    current = []    # collects rows for current frame\n",
    "\n",
    "     # Every time we see a \"Head\" joint, assume a new frame begins\n",
    "    for _, row in df.iterrows():\n",
    "        if row['Joint'] == 'Head' and current:\n",
    "            frames.append(pd.DataFrame(current))\n",
    "            current = []\n",
    "        current.append(row)\n",
    "    if current:\n",
    "        frames.append(pd.DataFrame(current))\n",
    "\n",
    "    # Determine the joint order from the first valid frame\n",
    "    joint_order = None\n",
    "    for fr in frames:\n",
    "        if 'Joint' in fr and fr['Joint'].nunique() >= 10:\n",
    "            joint_order = list(fr['Joint'])\n",
    "            break\n",
    "    if joint_order is None:\n",
    "        return None\n",
    "\n",
    "     # Create a 3D array: time × joints × coordinates\n",
    "    T = len(frames)\n",
    "    J = len(joint_order)\n",
    "    seq = np.full((T, J, 3), np.nan, dtype=float)\n",
    "\n",
    "     # Fill sequence array with x,y,z coordinates for each joint per frame\n",
    "    for t, fr in enumerate(frames):\n",
    "        # Map each joint name → (x, y, z)\n",
    "        name_to_xyz = {n: (x, y, z) for n, x, y, z in fr[['Joint', 'x', 'y', 'z']].itertuples(index=False)}\n",
    "        for j, name in enumerate(joint_order):\n",
    "            if name in name_to_xyz:\n",
    "                seq[t, j, :] = name_to_xyz[name]\n",
    "    return seq, joint_order\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
