{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b585fa19-1a8c-4f1e-9895-d23eb87ecf9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully yay!\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 1. IMPORT REQUIRED LIBRARIES\n",
    "# -------------------------------------------------------------\n",
    "# These libraries handle:\n",
    "# - file reading (os, glob, Path)\n",
    "# - numerical and data manipulation (numpy, pandas)\n",
    "# - machine learning preprocessing (scikit-learn)\n",
    "# - model building and saving (pickle)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "import os, re, glob, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "print(\"Libraries imported successfully yay!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a98b134f-2950-4083-99a5-69c2b7906427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found files: 180\n",
      "['CleanedKARDDataset\\\\RealWorldCoordinates\\\\a01_s01_e01_realworld.csv', 'CleanedKARDDataset\\\\RealWorldCoordinates\\\\a01_s02_e01_realworld.csv', 'CleanedKARDDataset\\\\RealWorldCoordinates\\\\a01_s03_e01_realworld.csv']\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 2. LOAD AND VERIFY DATASET\n",
    "# -------------------------------------------------------------\n",
    "# The dataset comes from the CleanedKARDDataset ZIP you uploaded.\n",
    "# Each CSV file represents one action clip containing 3D joint positions\n",
    "# in real-world coordinates (x, y, z) for different body joints.\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Change this path if your folder is stored elsewhere\n",
    "DATA_DIR = Path(\"CleanedKARDDataset/RealWorldCoordinates\")  # change if needed\n",
    "\n",
    "# Make sure the folder exists before continuing\n",
    "assert DATA_DIR.exists(), f\"Data dir not found: {DATA_DIR}\"\n",
    "\n",
    "\n",
    "# Collect all CSV files in the folder\n",
    "files = sorted(glob.glob(str(DATA_DIR / \"*.csv\")))\n",
    "print(\"Found files:\", len(files))\n",
    "\n",
    "# Preview first few file names\n",
    "print(files[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0faff85f-8257-42f6-a6d6-c33ea9b143f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 3. PARSE SEQUENCES INTO ARRAYS\n",
    "# -------------------------------------------------------------\n",
    "# Each CSV lists joint coordinates for multiple frames.\n",
    "# Reconstructing the frames so each file becomes:\n",
    "#     seq shape = (T, J, 3)\n",
    "# where:\n",
    "#   T = number of frames\n",
    "#   J = number of joints\n",
    "#   3 = x, y, z coordinates\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "def parse_sequence(csv_path: str):\n",
    "    \"\"\"\n",
    "    Convert a single CSV into a 3D numpy array [frames, joints, coords].\n",
    "    'Head' rows are used to detect new frames in the CSV stream.\n",
    "    Returns:\n",
    "        seq  -> np.ndarray of shape (T, J, 3)\n",
    "        joint_order -> list of joint names in consistent order\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    frames = []     # stores frame DataFrames\n",
    "    current = []    # collects rows for current frame\n",
    "\n",
    "     # Every time we see a \"Head\" joint, assume a new frame begins\n",
    "    for _, row in df.iterrows():\n",
    "        if row['Joint'] == 'Head' and current:\n",
    "            frames.append(pd.DataFrame(current))\n",
    "            current = []\n",
    "        current.append(row)\n",
    "    if current:\n",
    "        frames.append(pd.DataFrame(current))\n",
    "\n",
    "    # Determine the joint order from the first valid frame\n",
    "    joint_order = None\n",
    "    for fr in frames:\n",
    "        if 'Joint' in fr and fr['Joint'].nunique() >= 10:\n",
    "            joint_order = list(fr['Joint'])\n",
    "            break\n",
    "    if joint_order is None:\n",
    "        return None\n",
    "\n",
    "     # Create a 3D array: time × joints × coordinates\n",
    "    T = len(frames)\n",
    "    J = len(joint_order)\n",
    "    seq = np.full((T, J, 3), np.nan, dtype=float)\n",
    "\n",
    "     # Fill sequence array with x,y,z coordinates for each joint per frame\n",
    "    for t, fr in enumerate(frames):\n",
    "        # Map each joint name → (x, y, z)\n",
    "        name_to_xyz = {n: (x, y, z) for n, x, y, z in fr[['Joint', 'x', 'y', 'z']].itertuples(index=False)}\n",
    "        for j, name in enumerate(joint_order):\n",
    "            if name in name_to_xyz:\n",
    "                seq[t, j, :] = name_to_xyz[name]\n",
    "    return seq, joint_order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4786e06a-44f9-4939-aae9-c7fd278fa86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 4. PREPROCESS EACH SEQUENCE\n",
    "# -------------------------------------------------------------\n",
    "# To feed into ML, all sequences must have:\n",
    "# - the same number of frames (resampling)\n",
    "# - comparable scale (normalization)\n",
    "# - dynamic info (velocities)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "def resample_sequence(seq: np.ndarray, target_T: int = 60) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Resample sequence to a fixed number of frames (default 60)\n",
    "    by linear interpolation along the time dimension.\n",
    "    \"\"\"\n",
    "    T, J, C = seq.shape\n",
    "    src_t = np.arange(T)\n",
    "    dst_t = np.linspace(0, T - 1, target_T)\n",
    "    out = np.empty((target_T, J, C), dtype=float)\n",
    "\n",
    "    for j in range(J):\n",
    "        for c in range(C):\n",
    "            # Fill any missing (NaN) data before interpolation\n",
    "            y = pd.Series(seq[:, j, c]).ffill().bfill().to_numpy()\n",
    "            out[:, j, c] = np.interp(dst_t, src_t, y)\n",
    "    return out\n",
    "\n",
    "\n",
    "def root_center_normalize(seq: np.ndarray, joint_names: list, root_name: str = 'Torso') -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Center coordinates around the torso joint and scale\n",
    "    by the median head-to-torso distance.\n",
    "    \"\"\"\n",
    "    T, J, C = seq.shape\n",
    "    # identify root and head joints (fallback to 0 if missing)\n",
    "    root_idx = joint_names.index(root_name) if root_name in joint_names else 0\n",
    "    head_idx = joint_names.index('Head') if 'Head' in joint_names else 0\n",
    "\n",
    "    # Center by subtracting torso coordinates\n",
    "    centered = seq - seq[:, [root_idx], :]\n",
    "\n",
    "    # Compute typical human scale factor\n",
    "    d = np.linalg.norm(centered[:, head_idx, :] - centered[:, root_idx, :], axis=1)\n",
    "    scale = np.median(d) if np.isfinite(np.median(d)) and np.median(d) != 0 else 1.0\n",
    "\n",
    "    return centered / scale\n",
    "\n",
    "\n",
    "def make_features(seq: np.ndarray, include_velocity: bool = True) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert 3D sequence into a 1D feature vector:\n",
    "    - positions flattened across all frames and joints\n",
    "    - optional velocities (differences between consecutive frames)\n",
    "    \"\"\"\n",
    "    pos_flat = seq.reshape(-1)\n",
    "    feats = [pos_flat]\n",
    "\n",
    "    if include_velocity:\n",
    "        vel = np.diff(seq, axis=0)\n",
    "        feats.append(vel.reshape(-1))\n",
    "\n",
    "    return np.concatenate(feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7f61e5-3cbe-4556-b7cc-046050c503dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 6. LABEL ENCODING AND DATA SPLIT\n",
    "# -------------------------------------------------------------\n",
    "# Machine learning models require numerical labels.\n",
    "# LabelEncoder maps each motion type string (a01, a02, ...)\n",
    "# into an integer ID. We then split data 80/20 for training/testing.\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "\n",
    "# Split data, ensuring each class is proportionally represented\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_enc, test_size=0.2, stratify=y_enc, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train set: {X_train.shape}, Test set: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964991b1-ce6b-4cf9-b6a0-3c0c4c55cd59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e20cf82-cfd2-4b3a-b94b-90fdfb14ed8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
